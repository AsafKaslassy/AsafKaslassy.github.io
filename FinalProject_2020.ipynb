{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "FinalProject_2020.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsafKaslassy/AsafKaslassy.github.io/blob/master/FinalProject_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDdRXS1ZTH74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from glob import glob\n",
        "from pycocotools import coco\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "import pylab\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model, model_from_json\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Flatten, Dense, concatenate\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Softmax\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from plot_confusion_matrix import plot_confusion_matrix\n",
        "\n",
        "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "print (\"finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZjKfrWU6dE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GPU count and name\n",
        "!nvidia-smi -L\n",
        "\n",
        "!lscpu |grep 'Model name'\n",
        "\n",
        "#memory that we can use\n",
        "!free -h --si | awk  '/Mem:/{print $2}'\n",
        "print ('memory')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmZ6JAVF6jRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!df -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print('google drive train path: \"/content/drive/My Drive/train2017\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khs3iuVGTH7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_data(directory):\n",
        "# ==============================================================================\n",
        "#  This function gets a directory name and returns all images in it concatenated \n",
        "#  to each other\n",
        "# ==============================================================================    \n",
        "    data_list = glob(os.path.join(directory ,r'*.png'))\n",
        "    print(os.path.join(directory,'*.png'))\n",
        "    data = np.asarray([cv2.imread(img,0) for img in data_list])\n",
        "    return data\n",
        "\n",
        "print (\"finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncDivbzATH8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class TimeHistory(Callback):\n",
        "#     def on_train_begin(self, logs={}):\n",
        "#         self.times = []\n",
        "\n",
        "#     def on_epoch_begin(self, batch, logs={}):\n",
        "#         self.epoch_time_start = time.time()\n",
        "\n",
        "#     def on_epoch_end(self, batch, logs={}):\n",
        "#         self.times.append(time.time() - self.epoch_time_start)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XipUcn7jTH8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # display COCO categories and supercategories\n",
        "# cats = coco.loadCats(coco.getCatIds())\n",
        "# nms=[cat['name'] for cat in cats]\n",
        "# print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
        "\n",
        "# nms = set([cat['supercategory'] for cat in cats])\n",
        "# print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h36vgKnTH8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# the index of the image from the set just to visualize\n",
        "\n",
        "img_idx = 0\n",
        "\n",
        "# dataDir = \"D:\\FinalMscProject\\DeepLearning\"\n",
        "dataDir = \"/content/drive/My Drive\"\n",
        "\n",
        "train_data_name = \"train2017\"\n",
        "val_data_name = \"train2017\"\n",
        "\n",
        "# we resize the images because of memory limitations on my 32GB RAM and 4GB GPU memory\n",
        "img_width = 64\n",
        "img_height = 64\n",
        "\n",
        "# size of the data set for debug {None => all the data} \n",
        "max_cnt_debug_train = None\n",
        "max_cnt_debug_test = None\n",
        "\n",
        "# load images in grayscale or in RGB when rgb_on = 1 it will load rgb images\n",
        "rgb_on = 1\n",
        "\n",
        "# parameters for the training model number of classes will be autometicly generated based on the number of categories\n",
        "lr =          1e-3        # learning rate \n",
        "beta_1 =      0.9         # beta 1 - for adam optimizer\n",
        "beta_2 =      0.99        # beta 2 - for adam optimizer\n",
        "epsilon =     1e-7        # epsilon - for adam optimizer\n",
        "epochs =      50          # number of epochs\n",
        "bs =          32          # batch size\n",
        "dp =          0.5         # dropout probability\n",
        "\n",
        "\n",
        "# in the .getCatIds(catNms=[list of all ids we want to filter from the data]);\n",
        "categories_names = ['person']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfvgptF-2xwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpZbeiYKTH8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load captions\n",
        "#coco_caps= COCO(os.path.join(dataDir,r\"annotations\\captions_\" + data_name + \".json\"))\n",
        "\n",
        "# Load insatnces -> here we take the masks\n",
        "# coco_instances = COCO(os.path.join(dataDir,r\"annotations\\instances_\" + train_data_name + \".json\"))\n",
        "coco_instances = COCO(\"/content/drive/My Drive/annotations/instances_val2017.json\")\n",
        "\n",
        "# Load key points\n",
        "#coco_key_p = COCO(os.path.join(dataDir,r\"annotations\\person_keypoints_\" + data_name + \".json\")) \n",
        "\n",
        "# get the id for each category specified\n",
        "catIds = coco_instances.getCatIds(catNms=categories_names);\n",
        "\n",
        "#get all image id in the directory\n",
        "all_imgIds = coco_instances.getImgIds()\n",
        "\n",
        "# get all the image id for all images based on the filter\n",
        "imgIds = coco_instances.getImgIds(catIds=catIds);\n",
        "\n",
        "# get the data for each image id with specified annotations\n",
        "img_data = coco_instances.loadImgs(imgIds)\n",
        "\n",
        "# Visualize the img_idx specified up here\n",
        "I = io.imread(os.path.join(dataDir, train_data_name +r\"/\" +str(imgIds[img_idx]).zfill(12) + \".jpg\"))\n",
        "plt.imshow(I); \n",
        "plt.axis('off')\n",
        "plt.title(\"image id: \" + str(imgIds[img_idx]))\n",
        "\n",
        "# and show the mask on top of the image\n",
        "annIds = coco_instances.getAnnIds(imgIds=imgIds[img_idx], catIds=catIds, iscrowd=None)\n",
        "anns = coco_instances.loadAnns(annIds)\n",
        "coco_instances.showAnns(anns)\n",
        "\n",
        "#plot key points\n",
        "annIds_keys = coco_key_p.getAnnIds(imgIds=imgIds[idx], catIds=catIds, iscrowd=None)\n",
        "anns_keys = coco_key_p.loadAnns(annIds_keys)\n",
        "coco_key_p.showAnns(anns_keys)\n",
        "\n",
        "#print the caption\n",
        "annIds = coco_caps.getAnnIds(imgIds=imgIds[idx]);\n",
        "anns = coco_caps.loadAnns(annIds)\n",
        "coco_caps.showAnns(anns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55XQjqY7TH8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#visualize the mask of the annotaion\n",
        "# every annotation has a id (number) for every pixel on the mask we multiply by id\n",
        "# pixel = id = we have annotation in the pixel\n",
        "# pixel = 0 we dont have annotation in that spot\n",
        "anns_img = np.zeros((img_data[img_idx]['height'],img_data[img_idx]['width']))\n",
        "for ann in anns:\n",
        "    #mask += coco_instances.annToMask(anns[i])*anns[i]['category_id'] \n",
        "    anns_img = np.maximum(anns_img, coco_instances.annToMask(ann)*ann['category_id'])\n",
        "    \n",
        "#plt.subplot(2,1,1)    \n",
        "plt.imshow(anns_img)\n",
        "plt.axis('off')\n",
        "#plt.subplot(2,1,2)\n",
        "# Visuaslize the histogram of the mask\n",
        "#plt.hist(anns_img.ravel(),256, [0,50]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cso9IQyTH8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_list = [] # init empty list for masks\n",
        "\n",
        "# we load all the images in grayscale because of memory limitations\n",
        "img_list = [] # init empty list to store all the image data\n",
        "\n",
        "for cnt, imgID in enumerate(all_imgIds):\n",
        "    I = cv2.imread(os.path.join(dataDir, train_data_name +r\"//\" +str(imgID).zfill(12) + \".jpg\"), rgb_on)\n",
        "    I = cv2.resize(I, dsize=(img_width, img_height), interpolation=cv2.INTER_CUBIC)\n",
        "    img_list.append(I)\n",
        "    \n",
        "    if (imgID in imgIds):\n",
        "        # get all annotation ids for img id\n",
        "        annIds = coco_instances.getAnnIds(imgIds=imgID, catIds=catIds, iscrowd=None) \n",
        "        # load all annotation inside the image\n",
        "        anns = coco_instances.loadAnns(annIds) \n",
        "        # image data for image specification width height etc..\n",
        "        #img_data = coco_instances.loadImgs(imgID)[0] \n",
        "    \n",
        "        # init empty mask\n",
        "        anns_img = np.zeros((img_height, img_width),) \n",
        "        for ann in anns:\n",
        "            # resize the mask of the  specific anotation in the image\n",
        "            mask_res = cv2.resize(coco_instances.annToMask(ann), (img_height, img_width), interpolation = cv2.INTER_AREA )\n",
        "            # add the mask multiplid by the category index for category \n",
        "            # here we multiply by the index of the annotation +1\n",
        "            # for easier way to_categories\n",
        "            # if we have only one category it will be mask of only zeros ans ones\n",
        "            # if we would multiply by the category id the to_category will make more categories then we need\n",
        "            # for example if the category is 17 it will generate 18 categories and we need only 2\n",
        "            anns_img = np.maximum(anns_img, mask_res*(catIds.index(ann['category_id'])+1))\n",
        "    else:\n",
        "        anns_img = np.zeros((img_height, img_width),)\n",
        "    # for debug save the mask to the disk\n",
        "    #cv2.imwrite(r\"E:\\Documents\\Study\\Deep Learning\\Project\\MASKS\\\\\" +str(imgID).zfill(12) + \".png\" , anns_img)\n",
        "    mask_list.append(anns_img)\n",
        "    \n",
        "    if (cnt+1 == max_cnt_debug_train):\n",
        "        break\n",
        "\n",
        "# read the masks from the disk\n",
        "#y_train = read_data(r'E:\\Documents\\Study\\Deep Learning\\Project\\MASKS')\n",
        "#y_train = (to_categorical(y_train)).astype('float')\n",
        "\n",
        "y_train = np.asarray(mask_list)\n",
        "y_train = (to_categorical(y_train, num_classes=None, dtype='float32')).astype('float')\n",
        "\n",
        "x_train = np.asarray(img_list)\n",
        "if (rgb_on == 0):\n",
        "    x_train = (np.expand_dims(x_train, axis=3)).astype('float')\n",
        "\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_train shape:', x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vssZX7ycTH8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualize the first image from the set\n",
        "I = io.imread(os.path.join(dataDir, train_data_name +r\"//\" +str(imgIds[0]).zfill(12) + \".jpg\"))\n",
        "#I = cv2.cvtColor(I, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "#Visualize the image\n",
        "plt.subplot(2,1,1)    \n",
        "plt.imshow(I)\n",
        "plt.axis('off')\n",
        "#visualize the histogram of the image\n",
        "plt.subplot(2,1,2)   \n",
        "plt.hist(I.ravel(),256, [0,255]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO-bCvYWTH8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of classes for prediction based on the to_categorial\n",
        "num_of_clss = y_train.shape[3]  # number of classes (the number of the categories form the to_categorial by keras)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t-fqSztTH8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = Input(shape = (x_train.shape[1],x_train.shape[2],x_train.shape[3]))\n",
        "\n",
        "# First conv block\n",
        "x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(inp)\n",
        "x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(dp)(x)\n",
        "\n",
        "# Second conv block\n",
        "x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Third conv block\n",
        "x = Conv2D(16, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = Conv2D(16, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = Conv2D(16, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(dp)(x)\n",
        "# DECONV AND UNPOOLING\n",
        "\n",
        "x = Conv2DTranspose(16, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same', activation = 'relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "out = Conv2DTranspose(num_of_clss, (3, 3), strides=(1, 1), padding='same', activation = 'softmax')(x)\n",
        "\n",
        "model = Model(inp,out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKWQQ-CqTH8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y8smkuSTH81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the optimizer and compile the model\n",
        "adam = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "620ECOXbTH84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_callback = TimeHistory()\n",
        "history = model.fit(x_train, y_train, validation_split=0.3, epochs=epochs, batch_size=bs, callbacks=[time_callback])\n",
        "times = time_callback.times\n",
        "print(times)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNzF8tX_TH89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot train and validation loss \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show(); plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lZ9sCj1TH9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR9ap2XjTH9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9mhzbPTH9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load for validation different directrory different ids\n",
        "coco_instances = COCO(os.path.join(dataDir,r\"annotations\\instances_\" + val_data_name + \".json\"))\n",
        "\n",
        "# in the .getCatIds(catNms=[list of all ids we want to filter from the data]);\n",
        "catIds = coco_instances.getCatIds(catNms=categories_names);\n",
        "\n",
        "# get all the image id for all images here its for the validation\n",
        "all_imgIds = coco_instances.getImgIds();\n",
        "\n",
        "# get all the image id for all images based on the filter\n",
        "imgIds = coco_instances.getImgIds(catIds=catIds);\n",
        "\n",
        "img_list = []\n",
        "mask_list = []\n",
        "\n",
        "for cnt, imgID in enumerate(all_imgIds):\n",
        "    I = cv2.imread(os.path.join(dataDir, val_data_name +r\"//\" +str(imgID).zfill(12) + \".jpg\"),rgb_on)\n",
        "    I = cv2.resize(I, dsize=(img_width, img_height), interpolation=cv2.INTER_CUBIC)\n",
        "    img_list.append(I)\n",
        "    \n",
        "    if (imgID in imgIds):\n",
        "        annIds = coco_instances.getAnnIds(imgIds=imgID, catIds=catIds, iscrowd=None)\n",
        "        anns = coco_instances.loadAnns(annIds)\n",
        "        img_data = coco_instances.loadImgs(imgID)[0]\n",
        "        anns_img = np.zeros((img_height, img_width),)\n",
        "        for ann in anns:\n",
        "            mask_res = cv2.resize(coco_instances.annToMask(ann), (img_height, img_width), interpolation = cv2.INTER_AREA )\n",
        "            anns_img = np.maximum(anns_img, mask_res*(catIds.index((ann['category_id']))+1))\n",
        "        \n",
        "        #mask = cv2.resize(anns_img, dsize=(img_width, img_height), interpolation=cv2.INTER_CUBIC)    \n",
        "        #save mask to disk\n",
        "        #cv2.imwrite(r\"E:\\Documents\\Study\\Deep Learning\\Project\\TestMASKS\\\\\" +str(imgID).zfill(12) + \".png\" , mask)\n",
        "    else:\n",
        "        anns_img = np.zeros((img_height, img_width),)\n",
        "        \n",
        "    mask_list.append(anns_img)\n",
        "    \n",
        "    if (cnt+1 == max_cnt_debug_test):\n",
        "        break\n",
        "    \n",
        "#y_train = read_data(r'E:\\Documents\\Study\\Deep Learning\\Project\\MASKS')\n",
        "#y_train = (to_categorical(y_train)).astype('float')\n",
        "\n",
        "y_test = np.asarray(mask_list)\n",
        "#y_test = (np.expand_dims(y_test, axis=3)).astype('float')\n",
        "y_test = (to_categorical(y_test, num_classes=2, dtype='float32')).astype('float')\n",
        "\n",
        "\n",
        "x_test = np.asarray(img_list).astype('float')\n",
        "\n",
        "if (rgb_on == 0):\n",
        "    x_test = (np.expand_dims(x_test, axis=3)).astype('float')\n",
        "\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hMuwsWgTH9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplot(3,3,1)\n",
        "plt.imshow(np.squeeze(x_test[0,:,:].astype('uint8')))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3,3,2)\n",
        "plt.imshow(np.squeeze(x_test[1,:,:].astype('uint')))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3,3,3)\n",
        "plt.imshow(np.squeeze(x_test[2,:,:].astype('uint')))\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-8ejS6kTH9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.hist((coco_instances.annToMask(ann)*49).ravel(),256, [0,255]);\n",
        "#plt.hist(mask_list[0].ravel(),256, [0,255]);\n",
        "#plt.imshow(mask_list[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL-RK-8DTH9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = loaded_model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_mJ8riFTH9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print('test loss:', test_loss)\n",
        "print('test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if9ZSR3TTH9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Visialize the source image\n",
        "# img = cv2.imread(os.path.join(dataDir, data_name +r\"//\" +str(imgIds[0]).zfill(12) + \".jpg\"),0)\n",
        "# plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNxeTCBBTH9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visialize the resized image\n",
        "# visualize the predicted resaults vs the real resaults\n",
        "img_idx = 3\n",
        "\n",
        "if (rgb_on == 0):\n",
        "    plt.imshow((x_test[img_idx,:,:,0]).astype('uint8'))\n",
        "else:\n",
        "    plt.imshow((x_test[img_idx,:,:]).astype('uint8'))\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Qb1Uy6TH9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize the predicted resaults vs the real resaults\n",
        "\n",
        "plt.subplot(3,2,1)\n",
        "plt.imshow((y_pred[img_idx,:,:,0]*255).astype('uint8'))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3,2,2)\n",
        "plt.imshow((y_pred[img_idx,:,:,1]*255).astype('uint8'))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3,2,3)\n",
        "plt.imshow((y_test[img_idx,:,:,0]*255).astype('uint8'))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(3,2,4)\n",
        "plt.imshow((y_test[img_idx,:,:,1]*255).astype('uint8'))\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCKDZPTlTH9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auc roc for the good model the fist class\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr, tpr, _ = roc_curve(y_test[:,:,:,0].flatten(), y_pred[:,:,:,0].flatten())\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "plt.plot(fpr, tpr, color='green', lw=lw,label='ROC curve of class (AUC = {0})' ''.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic COCO person recognition')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAAae90HTH9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load 12 layers from the model\n",
        "layer_outputs = [layer.output for layer in loaded_model.layers] # Extracts the outputs of the top 12 layers\n",
        "activation_model = Model(inputs=loaded_model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_iMZLX5TH9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activations = activation_model.predict(x_test) # Returns a list of five Numpy arrays: one array per layer activation\n",
        "img_idx = 2\n",
        "plt.matshow(x_test[img_idx, :, :].astype('uint8'))\n",
        "plt.axis('off')\n",
        "for idx, act in enumerate(activations):\n",
        "    plt.subplot(8,4,idx+1)\n",
        "    plt.imshow(act[img_idx, :, :, 0], cmap='viridis')\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}